{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-981-32-9294-9_28/MediaObjects/483279_1_En_28_Fig1_HTML.png\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2025\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-981-32-9294-9_28/MediaObjects/483279_1_En_28_Fig1_HTML.png</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Regresión Logística</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logística es un algoritmo de machine learning para clasificación que es usado para predecir la probabilidad de variables dependientes categóricas. \n",
    "\n",
    "**Cuándo usar la regresión logística**\n",
    "\n",
    "- Clasificación Binaria: Cuando la variable dependiente tiene dos categorías. Ejemplo: predecir si un correo electrónico es \"spam\" o \"no spam\".\n",
    "- Estimación de probabilidad: cuando necesita estimar la probabilidad de que ocurra un evento.\n",
    "- Interpretabilidad: cuando se pretende comprender el impacto de las variables independientes en la probabilidad de un resultado particular.\n",
    "\n",
    "**Supuestos de regresión logística**\n",
    "\n",
    "- Requiere que las observaciones sean independientes entre sí\n",
    "- El algoritmo de regresión logística requiere poca o ninguna multicolinealidad entre las variables independientes. Significa que las variables independientes no deben estar demasiado correlacionadas entre sí.\n",
    "- El modelo de regresión logística supone linealidad de variables independientes y probabilidades logarítmicas.\n",
    "- El éxito del modelo de regresión logística depende del tamaño de la muestra. Normalmente, se requiere un tamaño de muestra grande para lograr una alta precisión.\n",
    "\n",
    "**¿Puede ser utilizada en problemas multiclase?**\n",
    "\n",
    "Sí... utiliza el método de One vs Rest (One vs all)\n",
    "Donde hace problemas binarios para cada combinación de clases y predice la clase con la probabilidad más alta. \n",
    "\n",
    "\n",
    "### En otro tema... lidiar con clases imbalanceadas en el target\n",
    "\n",
    "**¿Cómo saber cuándo hay que balancear las clases?**\n",
    "\n",
    "1. Imbalanceo severo. Cuando una clase es significativamente más frecuente (Ej. 90% vs 10% o peor). \n",
    "2. Importancia del problema a resolver. Si la clase minoritaria representa un resultado crítico (ej. detectar fraudes, diagnósticos médicos, fallas, etc.), balancear clases se vuelve necesario para evitar fallar en predicciones importantes. \n",
    "\n",
    "**¿Cuándo evitar el balanceo de clases?**\n",
    "1. Balanceo no tan severo. Si el imbalanceo es menor (ej. 60% vs 40%), balancear puede que no sea tan necesario y hasta puede ser perjudicial ya que puede llevar al overfitting. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "Se tienen datos de campañas de marketing (llamadas telefónicas) de un banco portugués. Se tiene la necesidad de predecir si un cliente va a suscribirse a un depósito a término (variable a predecir). \n",
    "\n",
    "Un depósito a término es un depósito que un banco ofrece con una tasa fija en la cual el dinero se regresará en cierto tiempo de madurez. \n",
    "\n",
    "\n",
    "### Los datos\n",
    "\n",
    "Los datos se obtuvieron del repositorio de UCI Machine learning https://archive.ics.uci.edu/ml/datasets/bank+marketing\n",
    "Consiste de 41188 datos. \n",
    "\n",
    "\n",
    "Variables de entrada:\n",
    "\n",
    "- age (numerica)\n",
    "- job : tipo de trabajo (categorica: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "- marital : estado marital (categorica: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "- education (categorica: basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "- housing: tiene hipoteca? (categorica: 'no','yes','unknown')\n",
    "- loan: tiene préstamos personales? (categorica: 'no','yes','unknown')\n",
    "- contact: tipo de comunicación (categorical: 'cellular','telephone')\n",
    "- month:último mes de contacto del año (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "- day_of_week: último día de contacto de la semana (categorical: 'mon','tue','wed','thu','fri')\n",
    "- duration: duración en segundos de la llamada. \n",
    "- campaign: número de llamadas realizadas durante esta campaña y para este cliente (numeric, includes last contact)\n",
    "- pdays: número de días que pasaron después de que el cliente fue contactado de la campaña anterior (numeric; 999 means client was not previously contacted)\n",
    "- previous: número de contactos realizados antes de esta campaña y para este cliente (numeric)\n",
    "- poutcome: resultado de la campaña de marketing anterior (categorical: 'failure','nonexistent','success')\n",
    "- emp.var.rate: tasa de variación del empleo - indicador trimestral (numeric)\n",
    "- cons.price.idx: índice de precios al consumidor - indicador mensual  (numeric)\n",
    "- cons.conf.idx: índice de confianza del consumidor - indicador mensual (numeric)\n",
    "- euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "\n",
    "\n",
    "Variable de salida:\n",
    "- y - se suscribió el cliente a un depósito a término? (binario: 'yes','no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar datos\n",
    "data = pd.read_csv('bank_full.csv')\n",
    "#Quitar valores nulos\n",
    "data = data.dropna()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cómo se ve la distribución de nuestra variable de salida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficando la distribucion de la variable a predecir\n",
    "sns.countplot(x='y', data=data)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos de salida están imbalanceados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver la distribución de las variables contra la variable de salida \"Y\" para empezar a ver qué variables podemos quitar o dejar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analizar variable Y vs estatus marital\n",
    "table=pd.crosstab(data.marital,data.y)\n",
    "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Estado marital vs compra')\n",
    "plt.xlabel('Estado marital')\n",
    "plt.ylabel('Proporcion de clientes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El estado marital no parece ser un predictor bueno para predecir la compra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analizar variable Y vs educación\n",
    "table=pd.crosstab(data.education,data.y)\n",
    "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Educacion vs compra')\n",
    "plt.xlabel('Educacion')\n",
    "plt.ylabel('Proporcion de clientes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La educación parece ser un buen predictor para la variable a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analizar variable Y vs día de la semana\n",
    "table=pd.crosstab(data.day_of_week,data.y)\n",
    "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Día de la semana vs compra')\n",
    "plt.xlabel('Día')\n",
    "plt.ylabel('Proporcion de clientes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El día de la semana puede no ser muy buen predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analizar variable Y vs mes\n",
    "table=pd.crosstab(data.month,data.y)\n",
    "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Mes vs compra')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Proporcion de clientes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mes puede ser un buen predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir X de Y\n",
    "X = data.loc[:,data.columns!='y']\n",
    "y = data.loc[:,data.columns=='y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir en test y train --> recordamos usar el stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='y', data=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpiar variables categóricas**\n",
    "\n",
    "Vamos a usar one-hot encoding para convertir variables categóricas a numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos las variables numericas de las categoricas\n",
    "numeric_features = X_train.select_dtypes(include=['float64', 'int64']).columns.values\n",
    "numeric_features = numeric_features[numeric_features != 'y']\n",
    "\n",
    "category_features = X_train.select_dtypes(include=['object', 'bool']).columns.values\n",
    "\n",
    "print(\"Variables numericas:\", numeric_features)\n",
    "print(\"Variables categoricas:\",category_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crean dos pipelines: uno para transformar las variables numéricas y otro para las categóricas.\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Se combina ambos transformadores (numérico y categórico) en un solo preprocesador que puede aplicarse a los datos para procesar todas las variables en conjunto.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, category_features)])\n",
    "\n",
    "ohe = preprocessor.fit(X_train)\n",
    "\n",
    "X_train_t = ohe.transform(X_train)\n",
    "X_test_t = ohe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aunque OneHotEncoder ya realiza la codificación de variables categóricas, la función dummify tiene dos propósitos:\n",
    "#1. Obtener los Nombres de las Columnas Generadas\n",
    "# 2. Convertir el Array Transformado en un DataFrame\n",
    "\n",
    "def dummify(ohe, x, columns):\n",
    "    transformed_array = ohe.transform(x)\n",
    "\n",
    "    enc = ohe.named_transformers_['cat'].named_steps['onehot']\n",
    "    feature_lst = enc.get_feature_names_out(category_features.tolist())   \n",
    "    \n",
    "    cat_colnames = np.concatenate([feature_lst]).tolist()\n",
    "    all_colnames = numeric_features.tolist() + cat_colnames \n",
    "    \n",
    "    df = pd.DataFrame(transformed_array, index = x.index, columns = all_colnames)\n",
    "    \n",
    "    return transformed_array, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t_array, X_train_t = dummify(ohe, X_train, category_features)\n",
    "X_test_t_array, X_test_t = dummify(ohe, X_test, category_features)\n",
    "\n",
    "X_train_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceo de clases (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordar que el balanceo de clases es después de dividir los datos en train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(random_state=0, n_jobs=1)\n",
    "\n",
    "#Hacer oversampling en datos del train\n",
    "os_data_X, os_data_y=os.fit_resample(X_train_t, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=X_train_t.columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto ya los datos están balanceados. Si se fijan sólo hicimos el oversampling en los datos de entrenamiento, ninguna de la información de los datos de test fueron usados para crear muestras sintéticas, por lo tanto ninguna información del test se filtra al entrenamiento del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='y', data=os_data_y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables\n",
    "\n",
    "Usamos el algoritmo de Recursive Feature Elimination (RFE) para seleccionar variables considerando cada vez menos y menos conjuntos de variables. \n",
    "\n",
    "RFE es fácil de configurar y bastante eficaz a la hora de seleccionar funciones en un conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#crear modelo de regresión logística\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=2000)\n",
    "\n",
    "#crear el recursive feature elimination para la regresión logística\n",
    "rfe = RFE(model, n_features_to_select=20, verbose=0)\n",
    "rfe = rfe.fit(os_data_X, os_data_y.values.ravel())\n",
    "print(\"Características seleccionadas: %s\" % rfe.support_)\n",
    "print(\"Rank de las características: %s\" % rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_columns = X_train_t.columns\n",
    "selected_columns = X_train_columns[rfe.support_]\n",
    "print(selected_columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = os_data_X[selected_columns.tolist()]\n",
    "y_train_final = os_data_y['y']\n",
    "X_test_final = X_test_t[selected_columns.tolist()]\n",
    "y_test_final = y_test\n",
    "\n",
    "X_test_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleccion de variables usando statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install stastmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementar modelo\n",
    "\n",
    "# statsmodels es un paquete que proporciona funciones para la estimación de muchos modelos estadísticos,\n",
    "#así como para realizar pruebas estadísticas y exploración de datos estadísticos.\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_train_final,X_train_final)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p value > 0.05, significa que podemos quitar la variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que terminamos de seleccionar variables, creamos el modelo de regresión logística. \n",
    "\n",
    "Pero antes... ¿Cómo interpretar estos coeficientes?\n",
    "\n",
    "- Para las variables numéricas que se les aplicó escalamiento: los coeficientes representan el efecto de un aumento de una desviación estándar en la variable sobre las probabilidades logarítmicas de la variable objetivo.\n",
    " \n",
    "Ejemplo: Para la variable de \"duration\". Un coeficiente de 1.83 significa que si la duración de la llamada aumenta en una desviación estándar por encima del promedio, las probabilidades de que el cliente acepte la oferta aumentan por un factor de 6.23.\n",
    "\n",
    "- Para las variables categóricas que se les aplicó el one-hot encoding: Los coeficientes de estas características binarias representan el cambio en las probabilidades logarítmicas de la variable objetivo al pasar de la categoría de referencia a la categoría representada por la característica.\n",
    "\n",
    "Ejemplo: Para la variable categórica \"month_nov\". El coeficiente negativo (-1.4411) indica que estar en noviembre disminuye significativamente las probabilidades de que los clientes acepten la oferta.\n",
    "Específicamente, estar en noviembre reduce las odds de aceptar la oferta a aproximadamente un 23.6%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regresión logítica con sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "#Inicializar objeto\n",
    "logreg = LogisticRegression()\n",
    "#Ajustar modelo a datos de entrenamiento\n",
    "logreg.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecir con datos del test\n",
    "y_pred = logreg.predict(X_test_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para clasificación usamos otras métricas diferentes a las de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
