{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://i0.wp.com/why-change.com/wp-content/uploads/2021/11/Decision-Tree-elements-2.png?resize=715%2C450&ssl=1\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2025\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://i0.wp.com/why-change.com/wp-content/uploads/2021/11/Decision-Tree-elements-2.png?resize=715%2C450&ssl=1</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Modelos basados en Árboles</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un árbol de decisión es un conjunto de sentencias de la forma: si... entonces...\n",
    "\n",
    "Estas sentencias dividen los datos en una serie de predictores. \n",
    "\n",
    "Estas divisiones de predictores son usadas para estimar la salida del modelo. \n",
    "\n",
    "**Ejemplo:** En un problema con dos predictores 'A' y 'B', un conjunto de sentencias de la forma:\n",
    "\n",
    "Si el predictor 'A' >= 1.7, entonces\n",
    "- Si el predictor B >=200, entonces la predicción = 1.3\n",
    "- De otra forma, la predicción = 2.5\n",
    "\n",
    "Estas sentencias están partiendo los predictores en 3 segmentos donde salidas específicas son definidas. \n",
    "\n",
    "**Estructura del árbol**\n",
    "\n",
    "Toma 3 cosas en cuenta:\n",
    "- Las variables predictoras (X) que se van a usar y el punto de partición del dataset.\n",
    "- La profundidad/complejidad del árbol\n",
    "- La ecuación de predicción en los últimos nodos/hojas del árbol\n",
    "\n",
    "**Hiperparámetros a ajustar**\n",
    "- Profundidad del árbol (max_depth)\n",
    "- Número mínimo de observaciones en cada split(min_samples_split)\n",
    "\n",
    "**Desventajas**\n",
    "\n",
    "- Inestabilidad del modelo: Debido a que las particiones se basan en un conjunto de datos, si se generan cambios en el conjunto de datos, esto genera cambios importantes en la estructura del árbol y especialmente en su interpretabilidad.\n",
    "\n",
    "- Rendimiento predictivo subóptimo. Nuevamente, debido a que las particiones se basan en un conjunto de datos específico, el modelo generalmente no converge con el modelo óptimo global.\n",
    "\n",
    "**Ventajas**\n",
    "\n",
    "- Son modelos interpretables\n",
    "- Manejan bien tanto variables numéricas como categóricas\n",
    "- Cada árbol individual se puede ver visualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.tree import DecisionTreeRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos -->\n",
    "# es un ejemplo donde vamos a observar información sobre casas de una inmobiliaria para predecir el precio de renta\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "square_footage = np.random.uniform(800, 4000, n_samples) \n",
    "num_rooms = np.random.randint(2, 7, n_samples)\n",
    "distance_to_city = np.random.uniform(0.5, 30, n_samples)\n",
    "\n",
    "# Variable del precio (no lineal)  y tiene ruido\n",
    "price = (square_footage * 200) + (num_rooms * 5000) - (distance_to_city * 1500)\n",
    "price += np.random.normal(0, 20000, n_samples)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Square Footage': square_footage,\n",
    "    'Number of Rooms': num_rooms,\n",
    "    'Distance to City (Miles)': distance_to_city,\n",
    "    'Price': price\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver datos\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observar datos\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Tamaño vs precio\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(data['Square Footage'], data['Price'], color='blue')\n",
    "plt.xlabel('Square Footage')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Square Footage vs Price')\n",
    "\n",
    "# Numero de cuartos vs precio\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(data['Number of Rooms'], data['Price'], color='green')\n",
    "plt.xlabel('Number of Rooms')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Number of Rooms vs Price')\n",
    "\n",
    "# Distancia ciudad vs precio\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(data['Distance to City (Miles)'], data['Price'], color='red')\n",
    "plt.xlabel('Distance to City (Miles)')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Distance to City vs Price')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar variables dependientes e independientes\n",
    "TargetVariable='Price'\n",
    "Predictors=['Square Footage','Number of Rooms','Distance to City (Miles)']\n",
    "X=data[Predictors].values\n",
    "y=data[TargetVariable].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividir en entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializar el modelo\n",
    "model = DecisionTreeRegressor(random_state = 0)\n",
    "# entrenar el modelo \n",
    "model.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediciendo en los datos de entrenamiento y prueba \n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular el error cuadrático medio\n",
    "mse = float(format(mean_squared_error(y_test, y_test_pred), '.3f'))\n",
    "print(\"\\nMSE: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcular la r2 en el test\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "print(\"\\nR2: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizar el árbol\n",
    "from sklearn import tree\n",
    "tree.plot_tree(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pareciera que el árbol está sobre-ajustando.. observemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafiquemos para ver si está sobreajustando\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Datos entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_train, y_train_pred, color=\"blue\")\n",
    "plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], color=\"red\", lw=2)\n",
    "plt.xlabel(\"True Prices (Train)\")\n",
    "plt.ylabel(\"Predicted Prices (Train)\")\n",
    "plt.title(\"Training Data Predictions\")\n",
    "\n",
    "# Datos de test\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_test_pred, color=\"green\")\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color=\"red\", lw=2)\n",
    "plt.xlabel(\"True Prices (Test)\")\n",
    "plt.ylabel(\"Predicted Prices (Test)\")\n",
    "plt.title(\"Test Data Predictions\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Imprimimos la R2 de entrenamiento y prueba\n",
    "print(f\"Training R^2: {model.score(x_train, y_train):.3f}\")\n",
    "print(f\"Testing R^2: {model.score(x_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmamos que el árbol está sobreajustando.... no bueno...\n",
    "\n",
    "Un gráfico que nos puede ayudar a darnos una idea sobre qué hiperparámetros podemos utilizar es graficar cada uno de los hiperparámetros probando con diferentes valores y observamos cómo van cambiando las métricas de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficamos la profundidad vs la R2\n",
    "max_depths = range(1, 21)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    tree_reg = DecisionTreeRegressor(max_depth=max_depth, random_state=42)\n",
    "    tree_reg.fit(x_train, y_train)\n",
    "    train_scores.append(tree_reg.score(x_train, y_train))\n",
    "    test_scores.append(tree_reg.score(x_test, y_test))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(max_depths, train_scores, label='Train $R^2$', color='blue', marker='o')\n",
    "plt.plot(max_depths, test_scores, label='Test $R^2$', color='green', marker='o')\n",
    "plt.xlabel('Tree Max Depth')\n",
    "plt.ylabel('$R^2$ Score')\n",
    "plt.title('Efecto de la profundidad del árbol en el Training y Test Performance')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficamos el min_sample_split vs la R2\n",
    "min_samples_splits = range(2, 30)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for min_samples_split in min_samples_splits:\n",
    "    tree_reg = DecisionTreeRegressor(min_samples_split=min_samples_split, random_state=42)\n",
    "    tree_reg.fit(x_train, y_train)\n",
    "    train_scores.append(tree_reg.score(x_train, y_train))\n",
    "    test_scores.append(tree_reg.score(x_test, y_test))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(min_samples_splits, train_scores, label='Train $R^2$', color='blue', marker='o')\n",
    "plt.plot(min_samples_splits, test_scores, label='Test $R^2$', color='green', marker='o')\n",
    "plt.xlabel('Min Sample Split')\n",
    "plt.ylabel('$R^2$ Score')\n",
    "plt.title('Efecto del min. numero de observaciones por split en el Training y Test Performance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Definimos la malla con los valores respectivos de cada hiperparámetro a probar\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 5],\n",
    "    'min_samples_split': [19,20]\n",
    "}\n",
    "\n",
    "# Inicializamos el modelo\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Inicializamos GridSearchCV con 5-fold cross-validation\n",
    "grid_search = GridSearchCV(tree_reg, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Entrenamos el modelo con los datos de entrenamiento\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir los mejores hiperparametros y el mejor score\n",
    "print(f\"Mejores hiperparametros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor score de R^2 con Cross-Validation: {grid_search.best_score_:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el mejor modelo en el set de entrenamiento y prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_train_pred = best_model.predict(x_train)\n",
    "y_test_pred = best_model.predict(x_test)\n",
    "\n",
    "\n",
    "# Test R^2 score\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test R^2 Score: {test_r2:.3f}\")\n",
    "\n",
    "# Train R^2 score\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "print(f\"Train R^2 Score: {test_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizar el árbol\n",
    "from sklearn import tree\n",
    "tree.plot_tree(\n",
    "decision_tree=best_model,\n",
    "feature_names=data.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "     tree.export_text(\n",
    "         decision_tree=best_model,\n",
    "         feature_names=data.drop(columns=['Price']).columns,\n",
    "     )\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ventajas de los árboles de decisión**\n",
    "\n",
    "- No requiere escalamiento de variables\n",
    "- Puede  ser usado para datos no lineales\n",
    "- Fácil de visualizar\n",
    "- Fácil de interpretar\n",
    "\n",
    "**Desventajas de los árboles de decisión**\n",
    "\n",
    "- Es computancionalmente complejo, especialmente al usar cross-validation para ajustar los hiperparámetros\n",
    "- Un cambio pequeño en los datos puede causar grandes cambios en la estructura del árbol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
